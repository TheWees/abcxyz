{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(821313, 99)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>helpful_label</th>\n",
       "      <th>wordcount_summary</th>\n",
       "      <th>wordcount_reviewText</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>ADJ_count</th>\n",
       "      <th>VERB_count</th>\n",
       "      <th>readability_summary</th>\n",
       "      <th>readability_reviewText</th>\n",
       "      <th>summary_reviewText</th>\n",
       "      <th>...</th>\n",
       "      <th>useful</th>\n",
       "      <th>defective</th>\n",
       "      <th>honest</th>\n",
       "      <th>late</th>\n",
       "      <th>personally</th>\n",
       "      <th>replace</th>\n",
       "      <th>responsive</th>\n",
       "      <th>return</th>\n",
       "      <th>review</th>\n",
       "      <th>Sub_Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>7.33</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>21.60</td>\n",
       "      <td>10.19</td>\n",
       "      <td>HDMI Nook adapter cable I am using this with a...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>22.00</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>14.53</td>\n",
       "      <td>16.07</td>\n",
       "      <td>Cheap proprietary scam The cable is very wobbl...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "      <td>20.00</td>\n",
       "      <td>11</td>\n",
       "      <td>21</td>\n",
       "      <td>2.40</td>\n",
       "      <td>12.63</td>\n",
       "      <td>A Perfdect Nook HD+ hook up This adaptor is re...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>84</td>\n",
       "      <td>14.00</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>9.07</td>\n",
       "      <td>22.51</td>\n",
       "      <td>A nice easy to use accessory. This adapter eas...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>185</td>\n",
       "      <td>37.00</td>\n",
       "      <td>14</td>\n",
       "      <td>38</td>\n",
       "      <td>8.51</td>\n",
       "      <td>19.77</td>\n",
       "      <td>This works great but read the details... This ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  helpful_label  wordcount_summary  wordcount_reviewText  \\\n",
       "0      5.0              1                  4                    22   \n",
       "1      2.0              0                  3                    22   \n",
       "2      5.0              0                  6                   120   \n",
       "3      4.0              0                  6                    84   \n",
       "4      5.0              1                  7                   185   \n",
       "\n",
       "   avg_sent_length  ADJ_count  VERB_count  readability_summary  \\\n",
       "0             7.33          1           4                21.60   \n",
       "1            22.00          2           4                14.53   \n",
       "2            20.00         11          21                 2.40   \n",
       "3            14.00         11          12                 9.07   \n",
       "4            37.00         14          38                 8.51   \n",
       "\n",
       "   readability_reviewText                                 summary_reviewText  \\\n",
       "0                   10.19  HDMI Nook adapter cable I am using this with a...   \n",
       "1                   16.07  Cheap proprietary scam The cable is very wobbl...   \n",
       "2                   12.63  A Perfdect Nook HD+ hook up This adaptor is re...   \n",
       "3                   22.51  A nice easy to use accessory. This adapter eas...   \n",
       "4                   19.77  This works great but read the details... This ...   \n",
       "\n",
       "   ...  useful  defective  honest  late  personally  replace  responsive  \\\n",
       "0  ...       0          0       0     0           0        0           0   \n",
       "1  ...       0          0       0     0           0        0           0   \n",
       "2  ...       0          0       0     0           0        0           0   \n",
       "3  ...       0          0       0     0           0        0           0   \n",
       "4  ...       0          0       0     0           0        0           0   \n",
       "\n",
       "   return  review  Sub_Cat  \n",
       "0       0       0        0  \n",
       "1       0       0        0  \n",
       "2       0       0        1  \n",
       "3       0       0        0  \n",
       "4       0       0        0  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features = pd.read_csv(\"final_model_df_wTextualCol.csv\")\n",
    "print(data_features.shape)\n",
    "data_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(821313, 99)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features = data_features.dropna()\n",
    "data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(821313, 97)\n",
      "(821313,)\n"
     ]
    }
   ],
   "source": [
    "X = data_features.drop('helpful_label', axis=1).drop('summary_reviewText', axis=1)\n",
    "print(X.shape)\n",
    "y = data_features['helpful_label']\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5153)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 --- Numerical Features derived from Review Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "features_logreg_pred_class = logreg.predict(X_test)\n",
    "features_prob = logreg.predict_proba(X_test)\n",
    "features_logreg_pred_prob = features_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg_feature Test Accuracy: 0.7089305456121638\n",
      "LogReg_feature Test AUC:  0.7084229342921956\n"
     ]
    }
   ],
   "source": [
    "logreg_accuracy = accuracy_score(y_test, features_logreg_pred_class)\n",
    "print('LogReg_feature Test Accuracy:', logreg_accuracy)\n",
    "auc = metrics.roc_auc_score(y_test, features_logreg_pred_prob)\n",
    "print('LogReg_feature Test AUC: ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 --- CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(max_features=5000, ngram_range=(1, 2), stop_words='english', min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_features.summary_reviewText\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5153)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "cvect_logreg_pred_class = logreg.predict(X_test_dtm)\n",
    "cvect_prob = logreg.predict_proba(X_test_dtm)\n",
    "cvect_logreg_pred_prob = cvect_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg_countvect Test Accuracy: 0.7220655630719479\n",
      "LogReg_countvect Test AUC:  0.7252610221004843\n"
     ]
    }
   ],
   "source": [
    "logreg_accuracy = accuracy_score(y_test, cvect_logreg_pred_class)\n",
    "print('LogReg_countvect Test Accuracy:', logreg_accuracy)\n",
    "auc = metrics.roc_auc_score(y_test, cvect_logreg_pred_prob)\n",
    "print('LogReg_countvect Test AUC: ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 --- TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(max_features=5000, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_features.summary_reviewText\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5153)\n",
    "y_train.shape\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "tfidfvect_logreg_pred_class = logreg.predict(X_test_dtm)\n",
    "tfidfvect_prob = logreg.predict_proba(X_test_dtm)\n",
    "tfidfvect_logreg_pred_prob = tfidfvect_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg_tfidf Test Accuracy: 0.7076058423310881\n",
      "LogReg_tfidf Test AUC:  0.7352403189692109\n"
     ]
    }
   ],
   "source": [
    "logreg_accuracy = accuracy_score(y_test, cvect_logreg_pred_class)\n",
    "print('LogReg_tfidf Test Accuracy:', logreg_accuracy)\n",
    "auc = metrics.roc_auc_score(y_test, tfidfvect_logreg_pred_prob)\n",
    "print('LogReg_tfidf Test AUC: ', auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling models 1, 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75650107 0.24349893]\n",
      "[0.73361028 0.26638972]\n",
      "[0.68225411 0.31774589]\n"
     ]
    }
   ],
   "source": [
    "print(features_prob[0, :])\n",
    "print(cvect_prob[0, :])\n",
    "print(tfidfvect_prob[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72412182, 0.27587818])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(features_prob[0, :] + cvect_prob[0, :] + tfidfvect_prob[0, :]) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.724122</td>\n",
       "      <td>0.275878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.803021</td>\n",
       "      <td>0.196979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.301975</td>\n",
       "      <td>0.698025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.273505</td>\n",
       "      <td>0.726495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.743084</td>\n",
       "      <td>0.256916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.724122  0.275878\n",
       "1  0.803021  0.196979\n",
       "2  0.301975  0.698025\n",
       "3  0.273505  0.726495\n",
       "4  0.743084  0.256916"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred_prob = pd.DataFrame((features_prob + cvect_prob + tfidfvect_prob) / 3, columns=logreg.classes_)\n",
    "new_pred_prob1 = (features_logreg_pred_prob + cvect_logreg_pred_prob + tfidfvect_logreg_pred_prob) / 3\n",
    "new_pred_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chene\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:56: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pred_class = new_pred_prob.apply(np.argmax, axis=1)\n",
    "new_pred_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Test Accuracy: 0.7229860370429896\n",
      "Ensemble Test AUC:  0.7395847851190251\n"
     ]
    }
   ],
   "source": [
    "logreg_accuracy = accuracy_score(y_test, new_pred_class)\n",
    "print('Ensemble Test Accuracy:', logreg_accuracy)\n",
    "\n",
    "auc = metrics.roc_auc_score(y_test, new_pred_prob1)\n",
    "print('Ensemble Test AUC: ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
