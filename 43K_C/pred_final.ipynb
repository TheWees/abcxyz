{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import * \n",
    "from dateutil.parser import parse\n",
    "\n",
    "import math\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_all = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "conf = (conf.setMaster('local[*]')\n",
    "        .set('spark.num.executors', '17')\n",
    "        .set('spark.executor.cores', '5')\n",
    "        .set('spark.executor.memory', '19g')\n",
    "        .set('spark.driver.memory', '19g')\n",
    "        .set('spark.network.timeout', '100001')\n",
    "        .set('spark.executor.heartbeatInterval', '100000')\n",
    "        .set('spark.rpc.askTimeout', '100000'))\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel(\"WARN\")\n",
    "spark = SparkSession(sc)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.driver.host', '192.168.51.29'),\n",
       " ('spark.executor.memory', '19g'),\n",
       " ('spark.rpc.askTimeout', '100000'),\n",
       " ('spark.executor.cores', '5'),\n",
       " ('spark.app.id', 'local-1551365998530'),\n",
       " ('spark.num.executors', '17'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.name', 'pyspark-shell'),\n",
       " ('spark.driver.memory', '19g'),\n",
       " ('spark.executor.heartbeatInterval', '100000'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.network.timeout', '100001'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.driver.port', '43712'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sc.getConf().getAll()\n",
    "sc._conf.getAll()\n",
    "# print(sc._conf.get('spark.driver.memory'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For running in server only\n",
    "t0 = time.time()\n",
    "didi_df = spark.read.format(\"csv\").option(\"header\", \"false\").option(\"mode\", \"DROPMALFORMED\") \\\n",
    "    .load(\"./DIDI_datasets/xian/gps_*\")\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"time taken {}\".format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken 4.352817535400391\n"
     ]
    }
   ],
   "source": [
    "# # For running in local in replace of the above (of cos can run in server too if u just want to run 1 file)\n",
    "# t0 = time.time()\n",
    "# didi_df = spark.read.format(\"csv\").option(\"header\", \"false\").option(\"mode\", \"DROPMALFORMED\") \\\n",
    "#     .load(\"test_sample3\") #test_sample3\n",
    "# t1 = time.time()\n",
    "# total = t1-t0\n",
    "# print(\"time taken {}\".format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+---------+--------+\n",
      "|             driveID|             orderID| timestamp|longitude|latitude|\n",
      "+--------------------+--------------------+----------+---------+--------+\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|1477646735|108.94724|34.26834|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|1477646705|108.94724| 34.2683|\n",
      "|364656e8019b2d863...|a97c5c2e4ff74307e...|1477650142| 108.9471|34.26965|\n",
      "|364656e8019b2d863...|a97c5c2e4ff74307e...|1477650139| 108.9471|34.26969|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|1477646624|108.94724|34.26751|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|1477646657|108.94724|34.26773|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|1477646798|108.94725|34.26916|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|1477646420|108.94723|34.26648|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|1477646330|108.94722|34.26633|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|1477646477|108.94723|34.26681|\n",
      "+--------------------+--------------------+----------+---------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "time taken 0.33379387855529785\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "didi_df = didi_df.toDF(\"driveID\",\"orderID\",\"timestamp\",\"longitude\",\"latitude\")\n",
    "didi_df.show(10)\n",
    "didi_df = didi_df.select(didi_df.driveID,didi_df.orderID,\n",
    "                        didi_df.timestamp.cast(DoubleType()),\n",
    "                        didi_df.longitude.cast(DoubleType()),\n",
    "                        didi_df.latitude.cast(DoubleType()))\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"time taken {}\".format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('driveID', 'string'), ('orderID', 'string'), ('timestamp', 'double'), ('longitude', 'double'), ('latitude', 'double')]\n",
      "root\n",
      " |-- driveID: string (nullable = true)\n",
      " |-- orderID: string (nullable = true)\n",
      " |-- timestamp: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+-------------+---------+--------+\n",
      "|             driveID|             orderID|    timestamp|longitude|latitude|\n",
      "+--------------------+--------------------+-------------+---------+--------+\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|1.477646735E9|108.94724|34.26834|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|1.477646705E9|108.94724| 34.2683|\n",
      "|364656e8019b2d863...|a97c5c2e4ff74307e...|1.477650142E9| 108.9471|34.26965|\n",
      "|364656e8019b2d863...|a97c5c2e4ff74307e...|1.477650139E9| 108.9471|34.26969|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|1.477646624E9|108.94724|34.26751|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|1.477646657E9|108.94724|34.26773|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|1.477646798E9|108.94725|34.26916|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...| 1.47764642E9|108.94723|34.26648|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...| 1.47764633E9|108.94722|34.26633|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|1.477646477E9|108.94723|34.26681|\n",
      "+--------------------+--------------------+-------------+---------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(didi_df.dtypes)\n",
    "didi_df.printSchema()\n",
    "didi_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # u may skip this chunk cos count() will take very long to run, run only when needed\n",
    "# t0 = time.time()\n",
    "# print(didi_df.count())\n",
    "# t1 = time.time()\n",
    "# total = t1-t0\n",
    "# print(\"time taken {}\".format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #u may skip this chunk cos count() will take very long to run, run only when needed\n",
    "# t0 = time.time()\n",
    "# didi_df_grouped = didi_df.groupBy(\"driveID\")\n",
    "# didi_df_grouped.count().show(10)\n",
    "# t1 = time.time()\n",
    "# total = t1-t0\n",
    "# print(\"time taken {}\".format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For running in server only\n",
    "# t0 = time.time()\n",
    "# didi_df.write.parquet(\"didi_31_files.parquet\")\n",
    "# t1 = time.time()\n",
    "# total = t1-t0\n",
    "# print(\"time taken {}\".format(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Once you saved in the file in parquet, you only need to start from this line after executing the 1st 2 chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For running in server only\n",
    "# t0 = time.time()\n",
    "# didi_new = sqlContext.read.parquet(\"didi_31_files.parquet\")\n",
    "# t1 = time.time()\n",
    "# total = t1-t0\n",
    "# print(\"time taken {}\".format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "didi_agg = didi_df.withColumn(\n",
    "        'timestamp',\n",
    "        from_unixtime(didi_df.timestamp, 'yyyy-MM-dd HH:mm:ss')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+---------+--------+---------+-------+\n",
      "|             driveID|             orderID|          timestamp|longitude|latitude|dayOfWeek|dayType|\n",
      "+--------------------+--------------------+-------------------+---------+--------+---------+-------+\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:25:35|108.94724|34.26834|        5|      0|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:25:05|108.94724| 34.2683|        5|      0|\n",
      "|364656e8019b2d863...|a97c5c2e4ff74307e...|2016-10-28 18:22:22| 108.9471|34.26965|        5|      0|\n",
      "|364656e8019b2d863...|a97c5c2e4ff74307e...|2016-10-28 18:22:19| 108.9471|34.26969|        5|      0|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:23:44|108.94724|34.26751|        5|      0|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:24:17|108.94724|34.26773|        5|      0|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:26:38|108.94725|34.26916|        5|      0|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:20:20|108.94723|34.26648|        5|      0|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:18:50|108.94722|34.26633|        5|      0|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:21:17|108.94723|34.26681|        5|      0|\n",
      "+--------------------+--------------------+-------------------+---------+--------+---------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "didi_agg = didi_agg.withColumn('dayOfWeek', date_format(didi_agg['timestamp'], 'u').cast(IntegerType()))\\\n",
    "    .withColumn('dayType', when((col(\"dayOfWeek\")==0)|(col(\"dayOfWeek\")==6) | \n",
    "                                ((col(\"timestamp\") >= lit('2016-10-01')) & (col(\"timestamp\") <= lit('2016-10-07'))), \n",
    "                                1).otherwise(0))\n",
    "didi_agg.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will take a long time, no need to run, just for check data\n",
    "# didi_agg.groupBy(\"dayOfWeek\").count().show()\n",
    "# didi_agg.groupBy(\"dayType\").count().show()\n",
    "# didi_agg = didi_agg.drop(\"dayOfWeek\", \"orderID\")\n",
    "# didi_agg.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+---------+--------+---------+-------+-------------+\n",
      "|             driveID|             orderID|          timestamp|longitude|latitude|dayOfWeek|dayType|timePartition|\n",
      "+--------------------+--------------------+-------------------+---------+--------+---------+-------+-------------+\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:25:35|108.94724|34.26834|        5|      0|         1045|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:25:05|108.94724| 34.2683|        5|      0|         1045|\n",
      "|364656e8019b2d863...|a97c5c2e4ff74307e...|2016-10-28 18:22:22| 108.9471|34.26965|        5|      0|         1102|\n",
      "|364656e8019b2d863...|a97c5c2e4ff74307e...|2016-10-28 18:22:19| 108.9471|34.26969|        5|      0|         1102|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:23:44|108.94724|34.26751|        5|      0|         1043|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:24:17|108.94724|34.26773|        5|      0|         1044|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:26:38|108.94725|34.26916|        5|      0|         1046|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:20:20|108.94723|34.26648|        5|      0|         1040|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:18:50|108.94722|34.26633|        5|      0|         1038|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:21:17|108.94723|34.26681|        5|      0|         1041|\n",
      "+--------------------+--------------------+-------------------+---------+--------+---------+-------+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- driveID: string (nullable = true)\n",
      " |-- orderID: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- dayOfWeek: integer (nullable = true)\n",
      " |-- dayType: integer (nullable = false)\n",
      " |-- timePartition: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def getTimePartition(timestamp):\n",
    "    dt = parse(timestamp)\n",
    "    timePart = int(datetime.strftime(dt, '%H'))*60 + int(datetime.strftime(dt, '%M'))\n",
    "    return timePart\n",
    "\n",
    "getTimePartitionUdf = udf(lambda timestamp: getTimePartition(timestamp), IntegerType())\n",
    "didi_agg_01 = didi_agg.withColumn(\"timePartition\", getTimePartitionUdf(\"timestamp\"))\n",
    "didi_agg_01.show(10)\n",
    "didi_agg_01.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+---------+--------+---------+-------+-------------+------------+------------+\n",
      "|             driveID|             orderID|          timestamp|longitude|latitude|dayOfWeek|dayType|timePartition|latPartition|lonPartition|\n",
      "+--------------------+--------------------+-------------------+---------+--------+---------+-------+-------------+------------+------------+\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:25:35|108.94724|34.26834|        5|      0|         1045|          83|          40|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:25:05|108.94724| 34.2683|        5|      0|         1045|          83|          40|\n",
      "|364656e8019b2d863...|a97c5c2e4ff74307e...|2016-10-28 18:22:22| 108.9471|34.26965|        5|      0|         1102|          84|          40|\n",
      "|364656e8019b2d863...|a97c5c2e4ff74307e...|2016-10-28 18:22:19| 108.9471|34.26969|        5|      0|         1102|          84|          40|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:23:44|108.94724|34.26751|        5|      0|         1043|          81|          40|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:24:17|108.94724|34.26773|        5|      0|         1044|          82|          40|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:26:38|108.94725|34.26916|        5|      0|         1046|          84|          40|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:20:20|108.94723|34.26648|        5|      0|         1040|          80|          40|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:18:50|108.94722|34.26633|        5|      0|         1038|          80|          40|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:21:17|108.94723|34.26681|        5|      0|         1041|          80|          40|\n",
      "+--------------------+--------------------+-------------------+---------+--------+---------+-------+-------------+------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latMin = 34.21012\n",
    "latMax = 34.28021\n",
    "lonMin = 108.91254\n",
    "lonMax = 108.99848\n",
    "\n",
    "# latMin = 34.21012 + 4*(0.07009/10)\n",
    "# latMax = 34.21012 + 6*(0.07009/10)\n",
    "# lonMin = 108.91254 + 4*(0.08594/10)\n",
    "# lonMax = 108.91254 + 6*(0.08594/10)\n",
    "\n",
    "def getLatPartition(lat):\n",
    "    latPart = math.floor(((lat - latMin) / (latMax - latMin)) * 100)\n",
    "    return latPart\n",
    "def getLonPartition(lon):\n",
    "    lonPart = math.floor(((lon - lonMin) / (lonMax - lonMin)) * 100)\n",
    "    return lonPart\n",
    "\n",
    "getLatPartitionUdf = udf(lambda latitude: getLatPartition(latitude), IntegerType())\n",
    "getLonPartitionUdf = udf(lambda longitude: getLonPartition(longitude), IntegerType())\n",
    "didi_agg_02 = didi_agg_01.withColumn(\"latPartition\", getLatPartitionUdf(\"latitude\"))\\\n",
    "    .withColumn(\"lonPartition\", getLonPartitionUdf(\"longitude\"))\\\n",
    "    .filter((col(\"latPartition\")>=0) & (col(\"lonPartition\")>=0))\n",
    "didi_agg_02.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+---------+-------+-------------+------------+------------+\n",
      "|             driveID|             orderID|          timestamp|dayOfWeek|dayType|timePartition|latPartition|lonPartition|\n",
      "+--------------------+--------------------+-------------------+---------+-------+-------------+------------+------------+\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:25:35|        5|      0|         1045|          83|          40|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:25:05|        5|      0|         1045|          83|          40|\n",
      "|364656e8019b2d863...|a97c5c2e4ff74307e...|2016-10-28 18:22:22|        5|      0|         1102|          84|          40|\n",
      "|364656e8019b2d863...|a97c5c2e4ff74307e...|2016-10-28 18:22:19|        5|      0|         1102|          84|          40|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:23:44|        5|      0|         1043|          81|          40|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:24:17|        5|      0|         1044|          82|          40|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:26:38|        5|      0|         1046|          84|          40|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:20:20|        5|      0|         1040|          80|          40|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:18:50|        5|      0|         1038|          80|          40|\n",
      "|364656e8019b2d863...|96767f0a20545dce7...|2016-10-28 17:21:17|        5|      0|         1041|          80|          40|\n",
      "+--------------------+--------------------+-------------------+---------+-------+-------------+------------+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- driveID: string (nullable = true)\n",
      " |-- orderID: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- dayOfWeek: integer (nullable = true)\n",
      " |-- dayType: integer (nullable = false)\n",
      " |-- timePartition: integer (nullable = true)\n",
      " |-- latPartition: integer (nullable = true)\n",
      " |-- lonPartition: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "didi_agg_02 = didi_agg_02.drop(\"longitude\", \"latitude\")\n",
    "didi_agg_02.show(10)\n",
    "didi_agg_02.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+---------+-------+-------------+------------+------------+----------------+-------------+\n",
      "|             driveID|             orderID|          timestamp|dayOfWeek|dayType|timePartition|latPartition|lonPartition|timestamp_in_min|distinct_cars|\n",
      "+--------------------+--------------------+-------------------+---------+-------+-------------+------------+------------+----------------+-------------+\n",
      "|55ef07ecd41116cb9...|7ebd7614ca4804d8e...|2016-10-28 16:45:14|        5|      0|         1005|          56|          30|        24627405|            1|\n",
      "|0e83068419cd179bb...|050be49a428bbaf04...|2016-10-28 10:47:18|        5|      0|          647|          58|          32|        24627047|            1|\n",
      "|0e83068419cd179bb...|050be49a428bbaf04...|2016-10-28 10:47:21|        5|      0|          647|          58|          32|        24627047|            1|\n",
      "|0e83068419cd179bb...|2434c86c417a6455a...|2016-10-28 19:14:43|        5|      0|         1154|          58|          32|        24627555|            1|\n",
      "|0e83068419cd179bb...|2434c86c417a6455a...|2016-10-28 19:14:46|        5|      0|         1154|          58|          32|        24627555|            1|\n",
      "|0e83068419cd179bb...|2434c86c417a6455a...|2016-10-28 19:14:40|        5|      0|         1154|          58|          32|        24627555|            1|\n",
      "|0e83068419cd179bb...|2434c86c417a6455a...|2016-10-28 19:14:37|        5|      0|         1154|          58|          32|        24627555|            1|\n",
      "|0e83068419cd179bb...|f0e671d15e2550f4a...|2016-10-28 21:01:39|        5|      0|         1261|          58|          32|        24627662|            1|\n",
      "|0e83068419cd179bb...|f0e671d15e2550f4a...|2016-10-28 21:01:48|        5|      0|         1261|          58|          32|        24627662|            1|\n",
      "|0e83068419cd179bb...|f0e671d15e2550f4a...|2016-10-28 21:01:45|        5|      0|         1261|          58|          32|        24627662|            1|\n",
      "+--------------------+--------------------+-------------------+---------+-------+-------------+------------+------------+----------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "time taken 2.195838689804077\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "import datetime\n",
    "from pyspark.sql.functions import year, month, dayofmonth\n",
    "# #convert string timestamp to timestamp type             \n",
    "# didi_agg_03 = didi_agg_02.withColumn('date', date_format(didi_agg_02['timestamp'], 'd').cast(IntegerType()))\n",
    "didi_agg_03 = didi_agg_02.withColumn('timestamp_in_min', \n",
    "                                     round((col(\"timestamp\").cast('timestamp').cast('long'))/60).cast('integer'))\n",
    "\n",
    "\n",
    "\n",
    "#create window with partition over date and location\n",
    "# w = (Window.partitionBy('latPartition','lonPartition')\\\n",
    "#          .orderBy(col(\"timestamp_simple\")).rangeBetween(-900, 900))\n",
    "w = (Window.partitionBy('latPartition','lonPartition')\\\n",
    "         .orderBy(col(\"timestamp_in_min\")).rangeBetween(-15, 15)) # dynamic time partition\n",
    "# w = (Window.partitionBy('timePartition','latPartition','lonPartition')) # static time partition\n",
    "\n",
    "#use collect_set and size functions to perform countDistinct over a window\n",
    "didi_agg_03 = didi_agg_03.withColumn('distinct_cars', size(collect_set(\"driveID\").over(w)))\n",
    "\n",
    "didi_agg_03.show(10)\n",
    "\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"time taken {}\".format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# didi_agg_03.groupBy(\"distinct_cars\").count().orderBy(desc(\"count\")).show()\n",
    "# print(didi_agg_03.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+------------+----------------------+\n",
      "|timestamp_in_min|latPartition|lonPartition|distinct_cars_in_a_min|\n",
      "+----------------+------------+------------+----------------------+\n",
      "|        24627698|          46|          12|                     2|\n",
      "|        24627568|          44|          42|                     2|\n",
      "|        24627568|          44|          43|                     2|\n",
      "|        24627698|          50|          12|                     2|\n",
      "|        24627698|          47|          12|                     2|\n",
      "|        24627698|          49|          12|                     2|\n",
      "|        24627027|          85|          73|                     1|\n",
      "|        24627216|          57|           2|                     1|\n",
      "|        24627554|          44|          59|                     1|\n",
      "|        24627390|          70|          66|                     1|\n",
      "+----------------+------------+------------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- timestamp_in_min: integer (nullable = true)\n",
      " |-- latPartition: integer (nullable = true)\n",
      " |-- lonPartition: integer (nullable = true)\n",
      " |-- distinct_cars_in_a_min: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view number of records per location per minute per minute\n",
    "didi_agg_04_grouped = didi_agg_03.groupBy(\"timestamp_in_min\", \"latPartition\", \"lonPartition\")\\\n",
    "    .agg(countDistinct('driveID').alias(\"distinct_cars_in_a_min\")).orderBy(desc(\"distinct_cars_in_a_min\"))\n",
    "didi_agg_04_grouped.show(10)\n",
    "didi_agg_04_grouped.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+------------+----------------------+------------------+\n",
      "|timestamp_in_min|latPartition|lonPartition|distinct_cars_in_a_min|           density|\n",
      "+----------------+------------+------------+----------------------+------------------+\n",
      "|        24627698|          49|          12|                     2|               2.0|\n",
      "|        24627698|          47|          12|                     2|               2.0|\n",
      "|        24627697|          46|          12|                     1|               1.5|\n",
      "|        24627698|          46|          12|                     2|               1.5|\n",
      "|        24627699|          50|          12|                     1|1.3333333333333333|\n",
      "|        24627698|          50|          12|                     2|1.3333333333333333|\n",
      "|        24627580|          44|          43|                     1|1.3333333333333333|\n",
      "|        24627697|          50|          12|                     1|1.3333333333333333|\n",
      "|        24627563|          44|          43|                     1|              1.25|\n",
      "|        24627564|          44|          43|                     1|              1.25|\n",
      "|        24627565|          44|          43|                     1|               1.2|\n",
      "|        24627568|          44|          43|                     2|               1.2|\n",
      "|        24627567|          44|          42|                     1|1.1428571428571428|\n",
      "|        24627582|          44|          42|                     1|1.1428571428571428|\n",
      "|        24627581|          44|          42|                     1|1.1428571428571428|\n",
      "|        24627577|          44|          42|                     1|1.1428571428571428|\n",
      "|        24627568|          44|          42|                     2|1.1428571428571428|\n",
      "|        24627580|          44|          42|                     1|1.1428571428571428|\n",
      "|        24627569|          44|          42|                     1|1.1428571428571428|\n",
      "|        24627641|          48|          40|                     1|               1.0|\n",
      "+----------------+------------+------------+----------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- timestamp_in_min: integer (nullable = true)\n",
      " |-- latPartition: integer (nullable = true)\n",
      " |-- lonPartition: integer (nullable = true)\n",
      " |-- distinct_cars_in_a_min: long (nullable = false)\n",
      " |-- density: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "didi_agg_05_grouped = didi_agg_04_grouped.withColumn('density', (avg(col(\"distinct_cars_in_a_min\"))).over(w))\n",
    "didi_agg_05_grouped.orderBy(desc(\"density\")).show(20)\n",
    "didi_agg_05_grouped.printSchema()\n",
    "# print(didi_agg_05_grouped.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- driveID: string (nullable = true)\n",
      " |-- orderID: string (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- dayOfWeek: integer (nullable = true)\n",
      " |-- dayType: integer (nullable = false)\n",
      " |-- timePartition: integer (nullable = true)\n",
      " |-- latPartition: integer (nullable = true)\n",
      " |-- lonPartition: integer (nullable = true)\n",
      " |-- timestamp_in_min: integer (nullable = true)\n",
      " |-- distinct_cars: integer (nullable = false)\n",
      "\n",
      "root\n",
      " |-- timestamp_in_min: integer (nullable = true)\n",
      " |-- latPartition: integer (nullable = true)\n",
      " |-- lonPartition: integer (nullable = true)\n",
      " |-- distinct_cars_in_a_min: long (nullable = false)\n",
      " |-- density: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "didi_agg_03.printSchema()\n",
    "didi_agg_05_grouped.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----------------+-------------+------------+------------+-------------+-------+\n",
      "|             driveID|dayType|timestamp_in_min|timePartition|latPartition|lonPartition|distinct_cars|density|\n",
      "+--------------------+-------+----------------+-------------+------------+------------+-------------+-------+\n",
      "|0e83068419cd179bb...|      0|        24627698|         1297|          49|          12|            2|    2.0|\n",
      "|55ef07ecd41116cb9...|      0|        24627698|         1297|          49|          12|            2|    2.0|\n",
      "|0e83068419cd179bb...|      0|        24627698|         1297|          49|          12|            2|    2.0|\n",
      "|55ef07ecd41116cb9...|      0|        24627698|         1297|          49|          12|            2|    2.0|\n",
      "|55ef07ecd41116cb9...|      0|        24627698|         1297|          49|          12|            2|    2.0|\n",
      "|0e83068419cd179bb...|      0|        24627698|         1297|          49|          12|            2|    2.0|\n",
      "|0e83068419cd179bb...|      0|        24627698|         1297|          49|          12|            2|    2.0|\n",
      "|55ef07ecd41116cb9...|      0|        24627698|         1298|          49|          12|            2|    2.0|\n",
      "|55ef07ecd41116cb9...|      0|        24627698|         1297|          49|          12|            2|    2.0|\n",
      "|55ef07ecd41116cb9...|      0|        24627698|         1297|          49|          12|            2|    2.0|\n",
      "+--------------------+-------+----------------+-------------+------------+------------+-------------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- driveID: string (nullable = true)\n",
      " |-- dayType: integer (nullable = false)\n",
      " |-- timestamp_in_min: integer (nullable = true)\n",
      " |-- timePartition: integer (nullable = true)\n",
      " |-- latPartition: integer (nullable = true)\n",
      " |-- lonPartition: integer (nullable = true)\n",
      " |-- distinct_cars: integer (nullable = false)\n",
      " |-- density: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "didi_agg_06 = didi_agg_03.join(didi_agg_05_grouped, \n",
    "                 [didi_agg_03.timestamp_in_min == didi_agg_05_grouped.timestamp_in_min,\n",
    "                 didi_agg_03.latPartition == didi_agg_05_grouped.latPartition,\n",
    "                 didi_agg_03.lonPartition == didi_agg_05_grouped.lonPartition])\\\n",
    "        .select(\"driveID\", \"dayType\",didi_agg_03.timestamp_in_min,\"timePartition\",\n",
    "               didi_agg_03.latPartition, didi_agg_03.lonPartition, \"distinct_cars\", \"density\")\\\n",
    "\n",
    "didi_agg_06.orderBy(desc(\"density\")).show(10)\n",
    "didi_agg_06.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+\n",
      "|             driveID|dayType|timestamp_in_min|timePartition|latPartition|lonPartition|traffic_flow_index|\n",
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+\n",
      "|0e83068419cd179bb...|      0|        24627567|         1167|          44|          41|               2.0|\n",
      "|0e83068419cd179bb...|      0|        24627567|         1167|          44|          41|               2.0|\n",
      "|55ef07ecd41116cb9...|      0|        24627569|         1168|          44|          41|               2.0|\n",
      "|0e83068419cd179bb...|      0|        24627567|         1166|          44|          41|               2.0|\n",
      "|55ef07ecd41116cb9...|      0|        24627569|         1168|          44|          41|               2.0|\n",
      "|55ef07ecd41116cb9...|      0|        24627569|         1168|          44|          41|               2.0|\n",
      "|0e83068419cd179bb...|      0|        24627567|         1167|          44|          41|               2.0|\n",
      "|0e83068419cd179bb...|      0|        24627567|         1166|          44|          41|               2.0|\n",
      "|0e83068419cd179bb...|      0|        24627582|         1182|          44|          41|               2.0|\n",
      "|0e83068419cd179bb...|      0|        24627567|         1167|          44|          41|               2.0|\n",
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- driveID: string (nullable = true)\n",
      " |-- dayType: integer (nullable = false)\n",
      " |-- timestamp_in_min: integer (nullable = true)\n",
      " |-- timePartition: integer (nullable = true)\n",
      " |-- latPartition: integer (nullable = true)\n",
      " |-- lonPartition: integer (nullable = true)\n",
      " |-- traffic_flow_index: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "didi_agg_07 = didi_agg_06.withColumn(\"traffic_flow_index\", col(\"distinct_cars\")/col(\"density\"))\\\n",
    "                    .drop(\"distinct_cars\", \"density\")\n",
    "didi_agg_07.orderBy(desc(\"traffic_flow_index\")).show(10)\n",
    "didi_agg_07.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+----------------------+\n",
      "|latPartition|lonPartition|avg_traffic_flow_index|\n",
      "+------------+------------+----------------------+\n",
      "|          44|          12|                   2.0|\n",
      "|          64|          36|                   2.0|\n",
      "|          45|          12|                   2.0|\n",
      "|          64|          35|                   2.0|\n",
      "|          52|          12|                   2.0|\n",
      "|          55|          12|                   2.0|\n",
      "|          64|          38|                   2.0|\n",
      "|          44|          46|    1.9583333333333333|\n",
      "|          44|          41|    1.9428571428571428|\n",
      "|          44|          44|    1.9310344827586208|\n",
      "|          64|          31|                 1.875|\n",
      "|          44|          45|                 1.875|\n",
      "|          44|          47|                   1.8|\n",
      "|          44|          42|                  1.75|\n",
      "|          44|          53|    1.7272727272727273|\n",
      "|          44|          50|    1.7272727272727273|\n",
      "|          44|          52|    1.6666666666666667|\n",
      "|          60|          30|    1.6470588235294117|\n",
      "|          44|          43|    1.6200000000000014|\n",
      "|          44|          54|                   1.6|\n",
      "+------------+------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------+------------+----------------------+\n",
      "|latPartition|lonPartition|avg_traffic_flow_index|\n",
      "+------------+------------+----------------------+\n",
      "|          56|          30|                   1.0|\n",
      "|          58|          32|                   1.0|\n",
      "|          58|          34|                   1.0|\n",
      "|          83|          11|                   1.0|\n",
      "|          18|          39|                   1.0|\n",
      "|          33|          39|                   1.0|\n",
      "|          34|           8|                   1.0|\n",
      "|          60|          69|                   1.0|\n",
      "|          85|          69|                   1.0|\n",
      "|          37|          59|                   1.0|\n",
      "|          41|          30|                   1.0|\n",
      "|          68|          69|                   1.0|\n",
      "|          70|          27|                   1.0|\n",
      "|          16|          39|                   1.0|\n",
      "|          30|          71|                   1.0|\n",
      "|          50|          48|                   1.0|\n",
      "|          59|          69|                   1.0|\n",
      "|          70|          50|                   1.0|\n",
      "|          77|          46|                   1.0|\n",
      "|          80|          58|                   1.0|\n",
      "+------------+------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see which block has the best / worst traffic flow\n",
    "didi_agg_08_grouped = didi_agg_07.groupBy('latPartition','lonPartition')\\\n",
    "        .agg(avg(\"traffic_flow_index\").alias(\"avg_traffic_flow_index\"))\n",
    "didi_agg_08_grouped.orderBy(desc(\"avg_traffic_flow_index\")).show()\n",
    "didi_agg_08_grouped.orderBy(\"avg_traffic_flow_index\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+\n",
      "|             driveID|dayType|timestamp_in_min|timePartition|latPartition|lonPartition|traffic_flow_index|\n",
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+\n",
      "|55ef07ecd41116cb9...|      0|        24627405|         1005|          56|          30|               1.0|\n",
      "|0e83068419cd179bb...|      0|        24627047|          647|          58|          32|               1.0|\n",
      "|0e83068419cd179bb...|      0|        24627047|          647|          58|          32|               1.0|\n",
      "|0e83068419cd179bb...|      0|        24627555|         1154|          58|          32|               1.0|\n",
      "|0e83068419cd179bb...|      0|        24627555|         1154|          58|          32|               1.0|\n",
      "|0e83068419cd179bb...|      0|        24627555|         1154|          58|          32|               1.0|\n",
      "|0e83068419cd179bb...|      0|        24627555|         1154|          58|          32|               1.0|\n",
      "|0e83068419cd179bb...|      0|        24627662|         1261|          58|          32|               1.0|\n",
      "|0e83068419cd179bb...|      0|        24627662|         1261|          58|          32|               1.0|\n",
      "|0e83068419cd179bb...|      0|        24627662|         1261|          58|          32|               1.0|\n",
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data cleaned for machine learning\n",
    "didi_final = didi_agg_07\n",
    "didi_final.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For running in server only\n",
    "t0 = time.time()\n",
    "didi_final.write.parquet(\"didi_31_files.parquet\")\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"time taken {}\".format(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple random forest model (default setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For running in server only\n",
    "t0 = time.time()\n",
    "didi_final = sqlContext.read.parquet(\"didi_31_files.parquet\")\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"time taken {}\".format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_rf = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+----+\n",
      "|             driveID|dayType|timestamp_in_min|timePartition|latPartition|lonPartition|traffic_flow_index|rank|\n",
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+----+\n",
      "|0e83068419cd179bb...|      0|        24626973|          572|          39|           0|               1.0| 0.0|\n",
      "|0e83068419cd179bb...|      0|        24626973|          573|          37|           4|               1.0| 0.0|\n",
      "|0e83068419cd179bb...|      0|        24626973|          573|          36|           4|               1.0| 0.0|\n",
      "|0e83068419cd179bb...|      0|        24626973|          573|          36|           4|               1.0| 0.0|\n",
      "|0e83068419cd179bb...|      0|        24626973|          573|          38|           2|               1.0| 0.0|\n",
      "|0e83068419cd179bb...|      0|        24626973|          573|          38|           2|               1.0| 0.0|\n",
      "|0e83068419cd179bb...|      0|        24626973|          573|          37|           3|               1.0| 0.0|\n",
      "|0e83068419cd179bb...|      0|        24626973|          573|          37|           3|               1.0| 0.0|\n",
      "|0e83068419cd179bb...|      0|        24626973|          573|          37|           3|               1.0| 0.0|\n",
      "|0e83068419cd179bb...|      0|        24626973|          572|          38|           0|               1.0| 0.0|\n",
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import percent_rank\n",
    "from pyspark.sql import Window\n",
    "#create a rank for time, for the convience of selecting training, validation and test data\n",
    "didi_df = didi_final.withColumn(\"rank\", percent_rank().over(Window.partitionBy().orderBy(\"timestamp_in_min\")))\n",
    "didi_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+\n",
      "|             driveID|dayType|timestamp_in_min|timePartition|latPartition|lonPartition|traffic_flow_index|\n",
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+\n",
      "|0e83068419cd179bb...|      0|        24626973|          572|          39|           0|               1.0|\n",
      "|0e83068419cd179bb...|      0|        24626973|          573|          37|           4|               1.0|\n",
      "|0e83068419cd179bb...|      0|        24626973|          573|          36|           4|               1.0|\n",
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+\n",
      "|             driveID|dayType|timestamp_in_min|timePartition|latPartition|lonPartition|traffic_flow_index|\n",
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+\n",
      "|4855017a1f4f7a00e...|      0|        24627681|         1280|          72|          12|               1.0|\n",
      "|4855017a1f4f7a00e...|      0|        24627681|         1280|          72|          12|               1.0|\n",
      "|4855017a1f4f7a00e...|      0|        24627681|         1280|          72|          12|               1.0|\n",
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+\n",
      "|             driveID|dayType|timestamp_in_min|timePartition|latPartition|lonPartition|traffic_flow_index|\n",
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+\n",
      "|55ef07ecd41116cb9...|      0|        24627711|         1311|          64|          32|               1.0|\n",
      "|55ef07ecd41116cb9...|      0|        24627711|         1311|          64|          32|               1.0|\n",
      "|55ef07ecd41116cb9...|      0|        24627711|         1311|          64|          32|               1.0|\n",
      "+--------------------+-------+----------------+-------------+------------+------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use the rank column to select the data for training, validation and test\n",
    "training_df = didi_df.where(\"rank <= 0.8\").drop(\"rank\")\n",
    "training_df.show(3)\n",
    "\n",
    "validation_df = didi_df.where(\"rank > 0.8\").where(\"rank <= 0.9\").drop(\"rank\")\n",
    "validation_df.show(3)\n",
    "\n",
    "test_df = didi_df.where(\"rank > 0.9\").where(\"rank <= 1.0\").drop(\"rank\")\n",
    "test_df.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- traffic_flow_index: double (nullable = true)\n",
      " |-- dayType: integer (nullable = false)\n",
      " |-- timePartition: integer (nullable = true)\n",
      " |-- latPartition: integer (nullable = true)\n",
      " |-- lonPartition: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- traffic_flow_index: double (nullable = true)\n",
      " |-- dayType: integer (nullable = false)\n",
      " |-- timePartition: integer (nullable = true)\n",
      " |-- latPartition: integer (nullable = true)\n",
      " |-- lonPartition: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- traffic_flow_index: double (nullable = true)\n",
      " |-- dayType: integer (nullable = false)\n",
      " |-- timePartition: integer (nullable = true)\n",
      " |-- latPartition: integer (nullable = true)\n",
      " |-- lonPartition: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features = ['dayType','timePartition','latPartition','lonPartition']  \n",
    "training = training_df.select(col(\"traffic_flow_index\"), *features)\n",
    "training.printSchema()  \n",
    "\n",
    "validation = validation_df.select(col(\"traffic_flow_index\"), *features)  \n",
    "validation.printSchema()  \n",
    "\n",
    "test = test_df.select(col(\"traffic_flow_index\"), *features) \n",
    "test.printSchema() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            features|traffic_flow_index|\n",
      "+--------------------+------------------+\n",
      "|[0.0,572.0,39.0,0.0]|               1.0|\n",
      "|[0.0,573.0,37.0,4.0]|               1.0|\n",
      "|[0.0,573.0,36.0,4.0]|               1.0|\n",
      "+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+------------------+\n",
      "|            features|traffic_flow_index|\n",
      "+--------------------+------------------+\n",
      "|[0.0,1280.0,72.0,...|               1.0|\n",
      "|[0.0,1280.0,72.0,...|               1.0|\n",
      "|[0.0,1280.0,72.0,...|               1.0|\n",
      "+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+------------------+\n",
      "|            features|traffic_flow_index|\n",
      "+--------------------+------------------+\n",
      "|[0.0,1311.0,64.0,...|               1.0|\n",
      "|[0.0,1311.0,64.0,...|               1.0|\n",
      "|[0.0,1311.0,64.0,...|               1.0|\n",
      "+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "vtraining = vector.transform(training)\n",
    "vtraining_df = vtraining.select(['features', 'traffic_flow_index'])\n",
    "vtraining_df.show(3)\n",
    "\n",
    "vvalidation = vector.transform(validation)\n",
    "vvalidation_df = vvalidation.select(['features', 'traffic_flow_index'])\n",
    "vvalidation_df.show(3)\n",
    "\n",
    "vtest = vector.transform(test)\n",
    "vtest_df = vtest.select(['features', 'traffic_flow_index'])\n",
    "vtest_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(labelCol='traffic_flow_index')\n",
    "rfr_model = rfr.fit(vtraining_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+--------------------+\n",
      "|        prediction|traffic_flow_index|            features|\n",
      "+------------------+------------------+--------------------+\n",
      "|1.0227964859078493|               1.0|[0.0,1280.0,72.0,...|\n",
      "|1.0227964859078493|               1.0|[0.0,1280.0,72.0,...|\n",
      "|1.0227964859078493|               1.0|[0.0,1280.0,72.0,...|\n",
      "|1.0227964859078493|               1.0|[0.0,1280.0,72.0,...|\n",
      "|1.0227964859078493|               1.0|[0.0,1280.0,72.0,...|\n",
      "+------------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on validation data = 0.306385\n"
     ]
    }
   ],
   "source": [
    "#for validation data\n",
    "rfr_predictions = rfr_model.transform(vvalidation_df)\n",
    "rfr_predictions.select(\"prediction\",\"traffic_flow_index\",\"features\").show(5)\n",
    "rfr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"traffic_flow_index\",metricName=\"rmse\")\n",
    "print(\"Root Mean Squared Error (RMSE) on validation data = %g\" % rfr_evaluator.evaluate(rfr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+--------------------+\n",
      "|        prediction|traffic_flow_index|            features|\n",
      "+------------------+------------------+--------------------+\n",
      "|1.1111412879701374|               1.0|[0.0,1311.0,64.0,...|\n",
      "|1.1111412879701374|               1.0|[0.0,1311.0,64.0,...|\n",
      "|1.1111412879701374|               1.0|[0.0,1311.0,64.0,...|\n",
      "|1.1111412879701374|               1.0|[0.0,1311.0,64.0,...|\n",
      "|1.1111412879701374|               1.0|[0.0,1311.0,64.0,...|\n",
      "+------------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.0382706\n"
     ]
    }
   ],
   "source": [
    "# for test data, run after load all data\n",
    "rfr_predictions = rfr_model.transform(vtest_df)\n",
    "rfr_predictions.select(\"prediction\",\"traffic_flow_index\",\"features\").show(5)\n",
    "rfr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"traffic_flow_index\",metricName=\"rmse\")\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rfr_evaluator.evaluate(rfr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken 87.91573405265808\n"
     ]
    }
   ],
   "source": [
    "t1_rf = time.time()\n",
    "total = t1_rf-t0_rf\n",
    "print(\"time taken {}\".format(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "features = ['dayType','timePartition','latPartition','lonPartition']  \n",
    "didi = didi_final.select(col(\"traffic_flow_index\"), *features)  \n",
    "didi.printSchema()  \n",
    "\n",
    "splits = vdidi_df.randomSplit([0.8, 0.2])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='traffic_flow_index', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_df)\n",
    "# Print the coefficients and intercept for linear regression\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "trainingSummary = lrModel.summary\n",
    "trainingSummary.residuals.show()\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions = lr_model.transform(test_df)\n",
    "lr_predictions.select(\"prediction\",\"traffic_flow_index\",\"features\").show(5) \n",
    "test_result = lr_model.evaluate(test_df)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Regression\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'traffic_flow_index')\n",
    "dt_model = dt.fit(train_df)\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_predictions.select('prediction', 'traffic_flow_index', 'features').show(5)\n",
    "dt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"MV\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosted Trees\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'traffic_flow_index', maxIter=10)\n",
    "gbt_model = gbt.fit(train_df)\n",
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "gbt_predictions.select('prediction', 'traffic_flow_index', 'features').show(5)\n",
    "\n",
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"MV\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken 410.7731158733368\n"
     ]
    }
   ],
   "source": [
    "# t0 = time.time()\n",
    "# didi_final.toPandas().to_csv('didi_final_20161028.csv')\n",
    "# t1 = time.time()\n",
    "# total = t1-t0\n",
    "# print(\"time taken {}\".format(total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken 155.9617211818695\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "rfr_predictions.toPandas().to_csv('rfr_predictions.csv')\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"time taken {}\".format(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get street name of the jam roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "latMin = 34.21012\n",
    "latMax = 34.28021\n",
    "lonMin = 108.91254\n",
    "lonMax = 108.99848\n",
    "\n",
    "latPartitionWidth = (latMax - latMin)/100\n",
    "lonPartitionWidth = (lonMax - lonMin)/100\n",
    "\n",
    "def getLatFromPartition(latPartition):\n",
    "    lat = latMin + latPartition*latPartitionWidth + latPartitionWidth/2\n",
    "    return lat\n",
    "def getLonFromPartition(lonPartition):\n",
    "    lon = lonMin + lonPartition*lonPartitionWidth + lonPartitionWidth/2\n",
    "    return lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.22168485\n",
      "34.21747945\n",
      "34.22168485\n",
      "108.9567991\n",
      "108.9860187\n",
      "108.9782841\n"
     ]
    }
   ],
   "source": [
    "print(getLatFromPartition(16))\n",
    "print(getLatFromPartition(10))\n",
    "print(getLatFromPartition(16))\n",
    "print(getLonFromPartition(51))\n",
    "print(getLonFromPartition(85))\n",
    "print(getLonFromPartition(76))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miko cafe, 雁塔西路（东段）, 曲江, 小寨路, 雁塔区 (Yanta), 西安市, 陕西省, 710061, 中国\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"didi_taxi\")\n",
    "location = geolocator.reverse(\"34.22168485, 108.9567991\")\n",
    "print(location.address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#青龙路, 大雁塔, 雁塔区 (Yanta), 西安市, 陕西省, 710055, 中国\n",
    "#慈恩东路, 曲江, 大雁塔, 雁塔区 (Yanta), 西安市, 陕西省, 710061, 中国\n",
    "#曲江大道, 曲江街办, 雁塔区 (Yanta), 西安市, 陕西省, 710055, 中国\n",
    "#东郡, 曲江街办, 雁塔区 (Yanta), 西安市, 陕西省, 中国\n",
    "#miko cafe, 雁塔西路（东段）, 曲江, 小寨路, 雁塔区 (Yanta), 西安市, 陕西省, 710061, 中国"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
